{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD2ciAJyaz1j5A/VNJqma9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thdusqpf/verlan/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vowels = ['a', 'e', 'i', 'o', 'u']\n",
        "\n",
        "identical_pronunciation = { 'i' : ['i', 'y'],\n",
        "                    'y' : ['y', 'u', 'eu'],\n",
        "                    'e' : ['e', 'ai', 'eiz'],\n",
        "                    'o' : ['o', 'au', 'eau'],\n",
        "                    'u' : ['ou', 'aou'],\n",
        "                    'f' : ['f', 'ph'],\n",
        "                    'k' : ['c', 'cc', 'k', 'que', 'ch'],\n",
        "                    'c' : ['q', 'que'],\n",
        "                    's' : ['s', 'sc', 'se', 'c', 'x', 'ch'],\n",
        "                    'z' : ['z', 's'],\n",
        "                    't' : ['tte'],\n",
        "                    'j' : ['ge']}\n",
        "\n",
        "!pip install unidecode\n",
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import SyllableTokenizer\n",
        "from nltk import word_tokenize\n",
        "import unicodedata\n",
        "from unidecode import unidecode\n",
        "#import alphabet\n",
        "\n",
        "verlan = input()\n",
        "\n",
        "def remove_accents(text):\n",
        "    if isinstance(text, str):\n",
        "        return unidecode(text)\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "def tokenize(text):\n",
        "  ssp = SyllableTokenizer()\n",
        "  return ssp.tokenize(text)\n",
        "\n",
        "def remove_stopword(text):\n",
        "  syllables = tokenize(text)\n",
        "  first_index = 0\n",
        "  last_index = len(syllables)-1\n",
        "\n",
        "  for i in (first_index, last_index):\n",
        "    last_alphabet_of_syllable = syllables[i][-1]\n",
        "    number_of_vowels = sum(word.count(vowel))\n",
        "\n",
        "    if (number_of_vowels>1 and last_alphabet_of_syllable == 'u'):\n",
        "      syllables[i] = syllables[i].strip('u')\n",
        "  return syllables\n",
        "\n",
        "def switch_syllables(text):\n",
        "  text.insert(0, text[-1])\n",
        "  return text[:-1]\n",
        "\n",
        "def handle_identical_pronounciation(text):\n",
        "  possible_word_tree = []\n",
        "\n",
        "  for alphabet in text:\n",
        "    for key in identical_pronunciation.keys():\n",
        "      if alphabet == key:\n",
        "        for value in identical_pronunciation[key]:\n",
        "          possible_word.append(text.replace(alphabet, value))\n",
        "  print(possible_word)\n",
        "\n",
        "verlan_without_accent = remove_accents(verlan)\n",
        "verlan_without_accent_stopword = remove_stopword(verlan_without_accent)\n",
        "switched_verlan_without_accent_stopword = switch_syllables(verlan_without_accent_stopword)\n",
        "print(switched_verlan_without_accent_stopword)\n",
        "preprocessed_verlan = handle_identical_pronounciation(switched_verlan_without_accent_stopword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "uQLZhvCtUEOh",
        "outputId": "4607dc46-7109-4006-9775-b0ba4496986c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.8)\n",
            "cimer\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'word' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8d38fbd565e3>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mverlan_without_accent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverlan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mverlan_without_accent_stopword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stopword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverlan_without_accent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mswitched_verlan_without_accent_stopword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch_syllables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverlan_without_accent_stopword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswitched_verlan_without_accent_stopword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-8d38fbd565e3>\u001b[0m in \u001b[0;36mremove_stopword\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfirst_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mlast_alphabet_of_syllable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msyllables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mnumber_of_vowels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvowel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber_of_vowels\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlast_alphabet_of_syllable\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'u'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'word' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "space_letter = ' '\n",
        "comma_letter = '\\''\n",
        "dash_letter = '-'\n",
        "special_letter = '’'\n",
        "special_letters = [space_letter, comma_letter, dash_letter,special_letter]"
      ],
      "metadata": {
        "id": "-0heO5GiTBRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "first_big_id = ord('A')\n",
        "last_big_id = ord('Z')\n",
        "first_small_id = ord('a')\n",
        "last_small_id = ord('z')\n",
        "\n",
        "big = list(range(first_big_id, last_big_id + 1))\n",
        "small = list(range(first_small_id, last_small_id + 1))\n",
        "\n",
        "english_letter_list = [chr(num) for num in big + small]\n",
        "\n",
        "english_letter_list.extend(special_letters)\n",
        "\n",
        "idx2english = dict(enumerate(english_letter_list, 1)) #1부터 시작\n",
        "print(idx2english.items())\n",
        "english2idx = {v: k for k, v in idx2english.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJm18vJuTDlQ",
        "outputId": "f39547cf-9381-48f5-835b-9642159ea0fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([(1, 'A'), (2, 'B'), (3, 'C'), (4, 'D'), (5, 'E'), (6, 'F'), (7, 'G'), (8, 'H'), (9, 'I'), (10, 'J'), (11, 'K'), (12, 'L'), (13, 'M'), (14, 'N'), (15, 'O'), (16, 'P'), (17, 'Q'), (18, 'R'), (19, 'S'), (20, 'T'), (21, 'U'), (22, 'V'), (23, 'W'), (24, 'X'), (25, 'Y'), (26, 'Z'), (27, 'a'), (28, 'b'), (29, 'c'), (30, 'd'), (31, 'e'), (32, 'f'), (33, 'g'), (34, 'h'), (35, 'i'), (36, 'j'), (37, 'k'), (38, 'l'), (39, 'm'), (40, 'n'), (41, 'o'), (42, 'p'), (43, 'q'), (44, 'r'), (45, 's'), (46, 't'), (47, 'u'), (48, 'v'), (49, 'w'), (50, 'x'), (51, 'y'), (52, 'z'), (53, ' '), (54, \"'\"), (55, '-'), (56, '’')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "xlsx = pd.read_excel('VerlanObjects_t.xlsx')\n",
        "xlsx.to_csv('VerlanObjects_t.csv')"
      ],
      "metadata": {
        "id": "TAXJ7iqzYch4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('VerlanObjects_t.csv', encoding='utf-8')\n",
        "del df['Unnamed: 0']\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ELqIMU8TLph",
        "outputId": "65638f35-b3b7-4344-a255-984a7aaa9a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Original', 'Verlan'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Load X\n",
        "verlan = df['Verlan'].apply(lambda x: np.array([english2idx[letter] for letter in x]))\n",
        "\n",
        "verlan_df = pd.DataFrame(verlan)\n",
        "\n",
        "X = pd.DataFrame(verlan_df['Verlan'].tolist()).values\n",
        "\n",
        "#Replace nan to 0\n",
        "X[np.isnan(X)] = 0\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LNjgMqdTZ3E",
        "outputId": "fca4ed30-f698-45dc-e836-574e0dfd41ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3. 27. 35. ...  0.  0.  0.]\n",
            " [ 2. 31. 47. ...  0.  0.  0.]\n",
            " [18. 31. 28. ...  0.  0.  0.]\n",
            " ...\n",
            " [44. 31. 28. ...  0.  0.  0.]\n",
            " [29. 34. 31. ...  0.  0.  0.]\n",
            " [28. 38. 31. ...  0.  0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_4IZHd4ij02",
        "outputId": "abff82d8-bdb3-4179-da71-a2d34999f138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(356, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Flip the input\n",
        "X = np.flip(X, axis = 1)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8hQiY9mionA",
        "outputId": "ed39a884-e42f-489b-8e4f-34a540ef6520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  0., ..., 35., 27.,  3.],\n",
              "       [ 0.,  0.,  0., ..., 47., 31.,  2.],\n",
              "       [ 0.,  0.,  0., ..., 28., 31., 18.],\n",
              "       ...,\n",
              "       [ 0.,  0.,  0., ..., 28., 31., 44.],\n",
              "       [ 0.,  0.,  0., ..., 31., 34., 29.],\n",
              "       [ 0.,  0.,  0., ..., 31., 38., 28.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Load Y\n",
        "original = df['Original'].apply(lambda x: np.array([english2idx[letter] for letter in x]))\n",
        "\n",
        "original_df = pd.DataFrame(original)\n",
        "\n",
        "Y = pd.DataFrame(original_df['Original'].tolist()).values\n",
        "\n",
        "#Replace nan to 0\n",
        "Y[np.isnan(Y)] = 0\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86iNGNFAiyvV",
        "outputId": "c41f93ea-d6ea-465b-c10a-466ac97a3ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1. 39. 31. ...  0.  0.  0.]\n",
            " [ 1. 44. 27. ...  0.  0.  0.]\n",
            " [ 1. 44. 27. ...  0.  0.  0.]\n",
            " ...\n",
            " [28. 41. 47. ...  0.  0.  0.]\n",
            " [28. 44. 27. ...  0.  0.  0.]\n",
            " [42. 41. 45. ...  0.  0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfKQXmN0joSc",
        "outputId": "d93925b7-d91e-41b3-f2cb-64c3c2978aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(356, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split train & test & validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.3)"
      ],
      "metadata": {
        "id": "tKhR1fULjvGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GRU  # GRU 레이어를 직접 임포트\n",
        "\n",
        "# Parameters for the model and dataset\n",
        "TRAINING_SIZE = 50000\n",
        "VOCAB_SIZE = 12\n",
        "INVERT = True\n",
        "HIDDEN_SIZE = 200\n",
        "BATCH_SIZE = 100\n",
        "LAYERS = 2\n",
        "MAX_EPOCHS = 1000\n",
        "EMBEDDING_OUTPUT_SIZE = 128\n",
        "# 이 부분은 X가 무엇인지에 따라 달라지므로, X를 적절히 정의해야 합니다.\n",
        "# 예를 들어, X가 훈련 데이터의 입력 행렬이라면, 그에 따른 적절한 값을 설정해야 합니다.\n",
        "MAX_SENT_LENGTH = X.shape[1] + 1\n",
        "\n",
        "# 사용하고자 하는 RNN 레이어를 직접 지정\n",
        "# 예시에서는 GRU를 사용하고 있으므로, 이를 직접 임포트하여 사용합니다.\n",
        "RNN = GRU\n",
        "stop_monitor = 'val_accuracy'  # 최신 버전에서는 'val_acc' 대신 'val_accuracy'를 사용\n",
        "stop_delta = 0.0  # minimum delta before early stop (default = 0)\n",
        "stop_epochs = 20    # how many epochs to do after stop condition (default = 0)\n"
      ],
      "metadata": {
        "id": "aSjFAlT3kHO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG, display\n",
        "# TensorFlow 2.x에서의 Keras 모듈 경로 사용\n",
        "from tensorflow.keras.utils import model_to_dot\n",
        "\n",
        "def viz_model(model):\n",
        "    display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))\n"
      ],
      "metadata": {
        "id": "Batx-yInk66K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, TimeDistributed, Activation, RepeatVector, Embedding, Dropout\n",
        "\n",
        "def build_model(embedding_input_dim,\n",
        "                embedding_output_dim,\n",
        "                embedding_input_length,\n",
        "                maximum_input_length,\n",
        "                hidden_size,\n",
        "                maximum_output_length,\n",
        "                encoder_layer_count,\n",
        "                dropout_rate,\n",
        "                output_classes_count,\n",
        "                rnn_layer,\n",
        "                summary_type=False):\n",
        "\n",
        "    print('Build model...')\n",
        "    RNN = rnn_layer\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Embedding(\n",
        "        input_dim=embedding_input_dim,\n",
        "        output_dim=embedding_output_dim,\n",
        "        input_length=embedding_input_length\n",
        "    ))\n",
        "\n",
        "    model.add(RNN(hidden_size, return_sequences=True, input_shape=(maximum_input_length, 123)))\n",
        "    model.add(RNN(hidden_size))\n",
        "\n",
        "    model.add(RepeatVector(maximum_output_length)) # 글자수 맥시멈\n",
        "\n",
        "    for _ in range(encoder_layer_count):\n",
        "        model.add(RNN(hidden_size, return_sequences=True))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # For each of step of the output sequence, decide which character should be chosen\n",
        "    model.add(TimeDistributed(Dense(output_classes_count)))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', # default: categorical_crossentropy\n",
        "                  optimizer='adam', # default: adam, can try SGD, RMSprop\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "    if summary_type is False:\n",
        "        pass\n",
        "    elif str(summary_type).lower() == 'svg':\n",
        "        viz_model(model)\n",
        "    else:\n",
        "        model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kw3feIplKNq",
        "outputId": "36128ebc-a67c-4540-9a72-5961f9980287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G74kF4LWomvY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}