{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWv+x745lpV7BawLQbSZkA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thdusqpf/verlan/blob/main/verlantoenglish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare special letter"
      ],
      "metadata": {
        "id": "GIGo2hh8N5VP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7hAGrwI_DquZ"
      },
      "outputs": [],
      "source": [
        "space_letter = ' '\n",
        "special_letters = [space_letter]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare English data"
      ],
      "metadata": {
        "id": "mdPA_b1dNywe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_big_id = ord('A')\n",
        "last_big_id = ord('Z')\n",
        "first_small_id = ord('a')\n",
        "last_small_id = ord('z')\n",
        "\n",
        "big = list(range(first_big_id, last_big_id + 1))\n",
        "small = list(range(first_small_id, last_small_id + 1))\n",
        "\n",
        "english_letter_list = [chr(num) for num in big + small]\n",
        "\n",
        "english_letter_list.extend(special_letters)\n",
        "\n",
        "idx2english = dict(enumerate(english_letter_list, 1)) #1부터 시작\n",
        "print(idx2english.items())\n",
        "english2idx = {v: k for k, v in idx2english.items()}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqkOFW1bDvPH",
        "outputId": "61e5d388-7f61-4a49-d72b-93fff54febf8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([(1, 'A'), (2, 'B'), (3, 'C'), (4, 'D'), (5, 'E'), (6, 'F'), (7, 'G'), (8, 'H'), (9, 'I'), (10, 'J'), (11, 'K'), (12, 'L'), (13, 'M'), (14, 'N'), (15, 'O'), (16, 'P'), (17, 'Q'), (18, 'R'), (19, 'S'), (20, 'T'), (21, 'U'), (22, 'V'), (23, 'W'), (24, 'X'), (25, 'Y'), (26, 'Z'), (27, 'a'), (28, 'b'), (29, 'c'), (30, 'd'), (31, 'e'), (32, 'f'), (33, 'g'), (34, 'h'), (35, 'i'), (36, 'j'), (37, 'k'), (38, 'l'), (39, 'm'), (40, 'n'), (41, 'o'), (42, 'p'), (43, 'q'), (44, 'r'), (45, 's'), (46, 't'), (47, 'u'), (48, 'v'), (49, 'w'), (50, 'x'), (51, 'y'), (52, 'z'), (53, ' ')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# xlsx to csv\n"
      ],
      "metadata": {
        "id": "hf618mY3KGV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xlsx = pd.read_excel('verlandataset.xlsx')\n",
        "xlsx.to_csv('verlandataset.csv')"
      ],
      "metadata": {
        "id": "E_b-pk8zKOBC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset from csv"
      ],
      "metadata": {
        "id": "GQ_By-wjNrEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('verlandataset.csv', encoding='utf-8')\n",
        "del df['Unnamed: 0']\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi3u-3k7EQ8W",
        "outputId": "a1378d3d-c469-48ed-accd-bdb44ee01de9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['verlan', 'original'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load X\n",
        "verlan = df['verlan'].apply(lambda x: np.array([english2idx[letter] for letter in x]))\n",
        "\n",
        "verlan_df = pd.DataFrame(verlan)\n",
        "\n",
        "X = pd.DataFrame(verlan_df['verlan'].tolist()).values\n",
        "\n",
        "#Replace nan to 0\n",
        "X[np.isnan(X)] = 0\n",
        "print(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk4hJ9WWJKRw",
        "outputId": "bd55e23c-4872-4bb5-8b07-5a81100dd64e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3. 27. 35. ...  0.  0.  0.]\n",
            " [ 2. 31. 47. ...  0.  0.  0.]\n",
            " [18. 31. 28. ...  0.  0.  0.]\n",
            " ...\n",
            " [13. 31. 47. ...  0.  0.  0.]\n",
            " [19. 31. 47. ...  0.  0.  0.]\n",
            " [20. 31. 47. ...  0.  0.  0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NzHPI5EWsq3",
        "outputId": "770ab5c0-b74b-4ba7-d313-5437c9cbf726"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Flip the input\n",
        "X = np.flip(X, axis = 1)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STGe7oSYhMOw",
        "outputId": "26f82862-fe5b-47ce-a50b-74f34d00ea74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.,  0.,  0., ..., 35., 27.,  3.],\n",
              "       [ 0.,  0.,  0., ..., 47., 31.,  2.],\n",
              "       [ 0.,  0.,  0., ..., 28., 31., 18.],\n",
              "       ...,\n",
              "       [ 0.,  0.,  0., ..., 47., 31., 13.],\n",
              "       [ 0.,  0.,  0., ..., 47., 31., 19.],\n",
              "       [ 0.,  0.,  0., ..., 47., 31., 20.]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split train & test & validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "bw4abQasc53x",
        "outputId": "fb6d1f9b-8742-4466-8c80-032e99077b5e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d7a74c1f5227>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Split train & test & validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get original X\n",
        "original_X_test = np.flip(x_test, axis = 1)\n",
        "original_X_test = [''.join([idx2english[j]for j in i if j != 0]) for i in original_X_test]"
      ],
      "metadata": {
        "id": "CSaW3-LPdXVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN\n",
        "- 순서가 있는 시퀀스 데이터를 입력받아 순서대로 하나씩 데이터 처리\n",
        "- 모든 입력 데이터를 한번에 처리하는 MLP, CNN 신경망과 차이점 존재\n",
        "- 다음 단어(정답)와 출력(예측)의 차이(cost function)를 최소화하는 가중치를 학습함.\n",
        "-레이어를 여러 개 거치면서 처음에 입력했던 단어에 대한 정보를 조금씩 잃어버림 -> 최근 학습 단어가 모델의 최종 예측에 더 큰 영향을 줌.\n",
        "\n",
        "##return_sequences 옵션\n",
        "- True: 모든 시간의 출력값을 그대로 다음 레이어에 전달\n",
        "- False or 지정 x: 최종 레이어의 출력만 반환"
      ],
      "metadata": {
        "id": "LiAuTfkQZ49k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM\n",
        "- RNN의 단점 보완 모델(오래 전에 학습한 데이터 기억 못함)\n",
        "- 기존 정보 중에서 중요한 정보를 다음 단계에 전달하는 구조 도입(장기 기억 성능 개선)\n",
        "- 길이 긴 시퀀스 데이터 학습에 적합\n"
      ],
      "metadata": {
        "id": "cFl-PTLAa1X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU\n",
        "- LSTM의 느린 학습 속도(시퀀스의 길이 길어지면 학습해야 할 가중치 파라미터의 개수가 기하급수적으로 증가) 개선 위해 제안된 알고리즘\n",
        "- LSTM의 셀을 단순한 구조로 변경 -> 모델의 파라미터 개수 줄이고 학습 속도 개선한 모델\n",
        "\n"
      ],
      "metadata": {
        "id": "KLnx6__4beKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seq2Seq\n",
        "참고 블로그:\n",
        "https://velog.io/@bobaebak/NLP-sequence-to-sequence%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%B4%EC%84%9C-%EB%B2%88%EC%97%AD%EA%B8%B0-%EB%A7%8C%EB%93%A4%EA%B8%B0"
      ],
      "metadata": {
        "id": "E0knNWYf12pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install recurrent\n",
        "from keras.layers import recurrent\n",
        "\n",
        "encoder_RNN = recurrent.LSTM\n",
        "decoder_RNN = recurrent.GRU\n",
        "stop_monitor = 'val_acc'\n",
        "stop_delta = 0.0\n",
        "stop_epochs = 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "gW8lZ5CyXIJU",
        "outputId": "81829da4-b001-41d6-b592-014e25567427"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting recurrent\n",
            "  Downloading recurrent-0.4.1.tar.gz (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting parsedatetime (from recurrent)\n",
            "  Downloading parsedatetime-2.6-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: recurrent\n",
            "  Building wheel for recurrent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for recurrent: filename=recurrent-0.4.1-py3-none-any.whl size=22213 sha256=8ecf450b056c20aa798a777f46eb4be1a2c1bf8ec1679cce00ad9558b4fee73a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/82/16/088f92476d450f3c52437c02ef91b61db47f332a54fef3c1d8\n",
            "Successfully built recurrent\n",
            "Installing collected packages: parsedatetime, recurrent\n",
            "Successfully installed parsedatetime-2.6 recurrent-0.4.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'recurrent' from 'keras.layers' (/usr/local/lib/python3.10/dist-packages/keras/layers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c79b07b6358b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install recurrent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoder_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoder_RNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'recurrent' from 'keras.layers' (/usr/local/lib/python3.10/dist-packages/keras/layers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#keras Sequential API\n",
        "- 레이어 여러 개를 연결하여 신경망 모델을 구성하는 도구\n",
        "\n",
        "- 간단한 아키텍처를 가지면서도 대부분의 딥러닝 모델을 만들 수 있음.\n",
        "\n",
        "##레이어\n",
        "- 임베딩(embedding): 말뭉치(corpus)를 입력하여 단어 사이의 유사도와 여러 가지 관계를 벡터로 표현 가능\n",
        "\n",
        "##용어\n",
        "- 입력 데이터의 차원(input_dim): 모델 학습에 사용하는 설명 변수(피처)의 개수 지정\n",
        "\n",
        "    ex)Y = aX + b에서 Y를 목표 변수(target), 목표 변수를 예측하는데 사용되는 X를 설명 변수(feature)라고 한다.\n",
        "- output_dim: 임베딩으로 변환되는 출력 벡터의 차원\n",
        "\n",
        "##summary 메서드\n",
        "- 모델 아키텍처(구조) 확인하는 메서드"
      ],
      "metadata": {
        "id": "5upsOx0ET-s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_OUTPUT_SIZE = 200\n",
        "\n",
        "# ## Build Model\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, TimeDistributed, Activation, RepeatVector, Embedding\n",
        "\n",
        "print('Build Model...')\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(\n",
        "    input_dim= len(english_letter_list) + 1,\n",
        "    output_dim=EMBEDDING_OUTPUT_SIZE,\n",
        "    input_length=X.shape[1]\n",
        "))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gt3yzUF6hRJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89c4862-2208-4329-a442-eee2d446a24a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build Model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 23, 200)           10800     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10800 (42.19 KB)\n",
            "Trainable params: 10800 (42.19 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(encoder_RNN(HIDDEN_SIZE, return_sequences=True, input_shape=(X.shape[1], )))\n",
        "model.add(encoder_RNN(HIDDEN_SIZE))\n",
        "\n",
        "model.add(RepeatVector(y.shape[1]))  # Maximum output length\n",
        "\n",
        "for _ in range(LAYERS):\n",
        "    model.add(decoder_RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "\n",
        "model.add(TimeDistributed(Dense(len(korean_letter_list)+1)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model.summary()\n",
        "print('Done')"
      ],
      "metadata": {
        "id": "pQxYRk73XCbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#제로 패딩\n",
        "- 딥러닝 모델에 입력하기 위해 입력 데이터의 크기 동일하게 조정\n",
        "\n",
        "    왜 동일해야 하나? 병렬 연산이 어렵기 때문에\n",
        "- 입력의 최대 길이(maxlen) 설정 후, 이보다 길이가 긴 경우 중간에 잘라서 길이를 맞추고, 짧은 경우에는 부족한만큼 숫자 0으로 채움.\n",
        "\n",
        "##패딩 방향 설정\n",
        "- default는 padding='pre'라서 앞에서부터 0을 채움.\n",
        "-padding='post' 뒤에서부터 0 채움."
      ],
      "metadata": {
        "id": "Q1yVqzhaeEVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model_name_to_read = './models/GRU2GRU_consonant-vowel_LSTM_flip_checkpoint'\n",
        "loaded_model = load_model(model_name_to_read)\n",
        "\n",
        "custom_input = ['crong', 'krong', 'hello', 'derek', 'rob', 'dennis']\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "custom_X = pad_sequences([[english2idx[letter] for letter in word] for word in custom_input], maxlen=X.shape[1], padding='post')\n",
        "\n",
        "custom_X = np.flip(custom_X, axis=1)\n",
        "\n",
        "custom_results = loaded_model.predict(custom_X)\n",
        "custom_argmax_result = np.argmax(custom_results, axis=2)\n",
        "custom_readable_results = [''.join([idx2korean[let] for let in one_result if let != 0]) for one_result in custom_argmax_result]"
      ],
      "metadata": {
        "id": "e9uwsd25eFlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oMYiqJ9igQog"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}