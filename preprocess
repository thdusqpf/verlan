!pip install unidecode

import pandas as pd
from nltk.tokenize import SyllableTokenizer
from nltk import word_tokenize
import unicodedata
from unidecode import unidecode

verlan = 'faus√©tu'

with open("alphabet.txt", "r") as file:
    identical_pronunciation = file.read()

def tokenize(text):
  ssp = SyllableTokenizer()
  syllables = ssp.tokenize(text)

def remove_stopword(text):
  first_index = 0
  last_index = len(syllables)-1
  last_alphabet_of_syllable = syllables[i][-1]

  tokenize(text)
  for i in (first_index, last_index):
    if (last_alphabet_of_syllable == 'u'):
      syllables[i] = syllables[i].strip('u')
  return syllables

def remove_accents(text):
    if isinstance(text, str):
        return unidecode(text)
    else:
        return text

def handle_identical_pronounciation(text):
  possible_word = []
  text = text.lower()

  tokenize(text)
  for alphabet in text:
    for key in identical_pronunciation.keys():
      if alphabet == key:
        for value in identical_pronunciation[key]:
          possible_word.append(text.replace(alphabet, value))
  print(possible_word)

verlan_without_accent = remove_accents(verlan)
verlan_without_accent_stopword = remove_stopword(verlan_without_accent)
preprocessed_verlan = handle_identical_pronounciation(verlan_without_accent_stopword)
